<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>From Keras to PyTorch | 环形缓冲</title>
<meta name="description" content="HXHC Blog" />
<link rel="shortcut icon" href="https://hxhc.xyz/favicon.ico?v=1715403560277">
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.0/animate.min.css" integrity="sha256-HtCCUh9Hkh//8U1OwcbD8epVEUdBvuI8wj1KtqMhNkI=" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/mermaid@8.11.0/dist/mermaid.min.js" integrity="sha256-sVAx+v/Q7v0Q2xm5vN7h5ccSna6gaLREhG9sF8pKT6I=" crossorigin="anonymous"></script> -->

<!-- <link href="
https://cdn.jsdelivr.net/npm/@openfonts/noto-serif-sc_chinese-simplified@1.44.2/index.min.css
" rel="stylesheet"> -->
<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link href="https://cdn.bootcdn.net/ajax/libs/remixicon/4.2.0/remixicon.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/animate.css/4.1.1/animate.min.css">
<script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.1.1/mermaid.min.js"></script>


<link rel="stylesheet" href="https://hxhc.xyz/styles/main.css">





  </head>

  <body>
    <div id="app" class="main px-4 flex flex-col lg:flex-row">
      <div id="sidebar" class="sidebar-wrapper lg:static lg:w-1/4">
  <div class="lg:sticky top-0">
    <div class="sidebar-content">
      <div class="flex lg:block p-4 lg:px-0 items-center fixed lg:static lg:block top-0 right-0 left-0 bg-white z-50">
        <i class="ri-menu-2-line lg:mt-4 text-2xl cursor-pointer animated fadeIn" onclick="openMenu()"></i>
        <a href="https://hxhc.xyz">
          <img class="animated fadeInLeft avatar rounded-lg mx-4 lg:mt-32 lg:mx-0 mt-0 lg:w-24 lg:h-24 w-12 w-12" src="https://hxhc.xyz/images/avatar.png?v=1715403560277" alt="">
        </a>
        <h1 class="animated fadeInLeft lg:text-4xl font-extrabold lg:mt-8 mt-0 text-xl" style="animation-delay: 0.2s">环形缓冲</h1>
      </div>
      
        <div class="animated fadeInLeft" style="animation-delay: 0.4s">
          <p class="my-4 text-gray-600 font-light hidden lg:block">
            Table of Contents
          </p>
          <div class="toc-container hidden lg:block">
            <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#cnn-mode-structure">CNN mode structure</a></li>
<li><a href="#keras-code">Keras code</a>
<ul>
<li><a href="#1-import-packages">1. Import  packages</a></li>
<li><a href="#2-prepare-data">2. Prepare data</a></li>
<li><a href="#3-build-model-and-create-callbacks">3. Build model and create callbacks</a></li>
<li><a href="#4-train-the-model">4. Train the model</a></li>
</ul>
</li>
<li><a href="#pure-pytorch-code">Pure Pytorch code</a>
<ul>
<li><a href="#1-import-packages-2">1. Import packages</a></li>
<li><a href="#2-prepare-data-2">2. Prepare data</a></li>
<li><a href="#3-define-the-model">3. Define the model</a></li>
<li><a href="#4-train-the-model-2">4. Train the model</a></li>
</ul>
</li>
<li><a href="#pytorch_lightning-code">Pytorch_Lightning code</a>
<ul>
<li><a href="#1-import-packages-3">1. Import packages</a></li>
<li><a href="#2-define-the-model">2. Define the model</a></li>
<li><a href="#3-create-callbacks">3. Create callbacks</a></li>
<li><a href="#4-train-the-model-3">4. Train the model</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      
    </div>
  </div>
</div>

<div class="menu-container">
  <i class="ri-arrow-left-line text-2xl cursor-pointer animated fadeIn close-menu-btn" onclick="closeMenu()"></i>
  <div>
    
      
        <a href="/" class="menu" style="animation-delay: 0s">
          Home
        </a>
      
    
      
        <a href="/archives" class="menu" style="animation-delay: 0.2s">
          Archives
        </a>
      
    
      
        <a href="/tags" class="menu" style="animation-delay: 0.4s">
          Tags
        </a>
      
    
      
        <a href="https://notes.hxhc.xyz" class="menu" style="animation-delay: 0.6000000000000001s" target="_blank">
          Notes
        </a>
      
    
      
        <a href="https://photos.hxhc.xyz" class="menu" style="animation-delay: 0.8s" target="_blank">
          Photo
        </a>
      
    
      
        <a href="/post/about" class="menu" style="animation-delay: 1s">
          About
        </a>
      
    
  </div>
  <div class="site-footer">
    <div class="py-4 text-gray-700">Great ideas in mind<br>
Poor words on paper</div>
    <a class="rss" href="https://hxhc.xyz/atom.xml" target="_blank">RSS</a>
  </div>
</div>
<div class="mask" onclick="closeMenu()" style="backdrop-filter: blur(7px); background: hsla(0, 0%, 100%, 0.5); -webkit-backdrop-filter: blur(7px);">
</div>
      <div class="content-wrapper py-32 lg:p-8 lg:w-3/4 post-detail animated fadeIn">
        <h1 class="text-3xl font-bold lg:mt-16">From Keras to PyTorch</h1>
        <div class="text-sm text-gray-700 lg:my-8">
          2021-08-22 / 12 min read
        </div>
        
          <img class="post-feature-image rounded-lg mx-auto my-4" src="https://i.morioh.com/19747ab0d7.png" alt="">
        
        <div class="post-content yue">
          <p>This post is to record the issues I encounted during the implementation from Keras to PyTorch. At first the structure of the CNN modes is introduced. Then,  the codes in Keras are shown. Next, The partial implementation in pure Pytorch is given and at last, the implementation in Pytorch Lightning is also presented.</p>
<!-- more -->
<p>Several days ago, my first research paper was published online . The research aimed to develop calibration models of UV spectra using CNNs. The research showed that the <mark>different loss functions</mark> might make a significant impact on the performance metrics. The results showed that CNN models with MAPE or MAE as the loss function predicted the spectra samples more accurately than those with MSE as the loss function.</p>
<p>I used <a href="https://keras.io/">Keras</a>) to conduct the experiments at that time. Recently I have been learning <a href="https://pytorch.org/">PyTorch</a> and thus, I try to implemented the models using Pytorch.</p>
<h2 id="cnn-mode-structure">CNN mode structure</h2>
<p>The model consists of 7 layers.</p>
<figure data-type="image" tabindex="1"><img src="https://tva4.sinaimg.cn/large/88eff492ly1gtovx5y27sj22zf223na4.jpg" alt="Structure" loading="lazy"></figure>
<center>The CNN model structure</center> 
<p><code>Conv</code>: the convolutional layer; <code>BN</code>: the batch normalization layer; <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span></span>: the activation function</p>
<p>Each spectrum vector (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>×</mo><mn>2016</mn></mrow><annotation encoding="application/x-tex">1 \times 2016</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">1</span><span class="mord">6</span></span></span></span>) is feeded into the the input layer, and then the features are extracted after the convolutional layer. The batchnorm layer could standardize the data, which allows no preprocessing on the spectra. Moreover, the batchnorm layer allows faster convergence. The dropout layer helps the model avoid overfitting.</p>
<h2 id="keras-code">Keras code</h2>
<h3 id="1-import-packages">1. Import  packages</h3>
<pre><code class="language-python">import tensorflow as tf
from tensorflow import keras # the version of tensorflow is 2.1.0
from tensorflow.keras.layers import (Dense, Conv1D, Flatten, Activation, BatchNormalization, Dropout)
from tensorflow.keras import Sequential, regularizers, optimizers
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)
</code></pre>
<h3 id="2-prepare-data">2. Prepare data</h3>
<pre><code class="language-python">data = pd.read_csv(&quot;./data.csv&quot;)

# dataset split
train = data[data['split'] == &quot;Calibration&quot;]
val = data[data['split'] == &quot;Validation&quot;]
test = data[data['split'] == &quot;Test&quot;]

Xtrain, ytrain = train.iloc[:, 5:], train.iloc[:, 3]
Xval, yval = val.iloc[:, 5:], val.iloc[:, 3]
Xtest, ytest = test.iloc[:, 5:], test.iloc[:, 3]

Xtrain, ytrain = Xtrain.values, ytrain.values,
Xval, yval = Xval.values, yval.values
Xtest, ytest = Xtest.values, ytest.values

# reshape the arrays from 1D to 2D
Xtrain = Xtrain.reshape(Xtrain.shape[0], Xtrain.shape[1], 1)
Xval = Xval.reshape(Xval.shape[0], Xval.shape[1], 1)
Xtest = Xtest.reshape(Xtest.shape[0], Xtest.shape[1], 1)

</code></pre>
<h3 id="3-build-model-and-create-callbacks">3. Build model and create callbacks</h3>
<pre><code class="language-python">
# Function: build the CNN model with different parameters like filters, l2.
def build_model(filters=8, kernel_size=200, l2=0.0001, dropout_ratio=0.2, units=32):
    model = Sequential()

    # the convolutional layer with ReLu activation
    model.add(
        Conv1D(filters=filters,
               kernel_size=kernel_size,
               strides=1,
               activation='relu',
               padding='same',
               input_shape=(Xtrain.shape[1], 1),
               kernel_initializer='VarianceScaling',
               kernel_regularizer=regularizers.l2(l2)))

    model.add(Flatten())
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(dropout_ratio))
    model.add(Dense(units, kernel_initializer='VarianceScaling', kernel_regularizer=regularizers.l2(l2)))

    # the output layer
    model.add(Dense(1))
    return model


# build model
model = build_model(filters=2, kernel_size=11, l2=0.1, dropout_ratio=0.1, units=32)
optimizer = optimizers.Adam(lr=0.0001)

# use earlystop to avoid overfitting and to save training time
earlystop = keras.callbacks.EarlyStopping(patience=500)

# use checkpoint to save the best model while training
if os.path.isdir(&quot;./best&quot;):
    pass
else:
    os.mkdir(&quot;./best&quot;)
weight_path = &quot;./best/weights_best.hdf5&quot;
checkpoint = keras.callbacks.ModelCheckpoint(weight_path, monitor='val_loss', verbose=0, save_best_only=True)

# define the loss function: 'mse'/'mape'/'mae'
model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])

</code></pre>
<h3 id="4-train-the-model">4. Train the model</h3>
<pre><code class="language-python">
# model training process
history = model.fit(
    x=Xtrain,
    y=ytrain,
    batch_size=64,  # mini-batch size
    epochs=1000,
    verbose=0,
    validation_data=(Xval, yval),
    callbacks=[earlystop, checkpoint])
del history

# load the best model weights during training for predictions
model.load_weights(weight_path)
ypred_test = model.predict(Xtest)
ypred_train = model.predict(Xtrain)
ypred_val = model.predict(Xval)
</code></pre>
<h2 id="pure-pytorch-code">Pure Pytorch code</h2>
<h3 id="1-import-packages-2">1. Import packages</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader

device = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)
</code></pre>
<h3 id="2-prepare-data-2">2. Prepare data</h3>
<pre><code class="language-python">data = pd.read_csv(&quot;./data.csv&quot;)

# dataset split
train = data[data['split'] == &quot;Calibration&quot;]
val = data[data['split'] == &quot;Validation&quot;]
test = data[data['split'] == &quot;Test&quot;]
Xtrain, ytrain = train.iloc[:, 5:], train.iloc[:, 3]
Xval, yval = val.iloc[:, 5:], val.iloc[:, 3]
Xtest, ytest = test.iloc[:, 5:], test.iloc[:, 3]

Xtrain, ytrain = Xtrain.values, ytrain.values,
Xval, yval = Xval.values, yval.values
Xtest, ytest = Xtest.values, ytest.values

Xtrain = Xtrain.reshape(-1, 1, 2016)
Xval = Xval.reshape(-1, 1, 2016)
Xtest = Xtest.reshape(-1, 1, 2016)

ytrain = ytrain.reshape(-1, 1)
yval = yval.reshape(-1, 1)
ytest = ytest.reshape(-1, 1)

# transform the numpy arrays to tensors
Xtrain_t = torch.from_numpy(Xtrain).type(torch.float).to(device)
Xval_t = torch.from_numpy(Xval).type(torch.float).to(device)
Xtest_t = torch.from_numpy(Xtest).type(torch.float).to(device)

ytrain_t = torch.from_numpy(ytrain).type(torch.float).to(device)
yval_t = torch.from_numpy(yval).type(torch.float).to(device)
ytest_t = torch.from_numpy(ytest).type(torch.float).to(device)

# create datasets and dataloaders
dataset_train = TensorDataset(Xtrain_t, ytrain_t)
dataset_val = TensorDataset(Xval_t, yval_t)
dataset_test = TensorDataset(Xtest_t, ytest_t)

train_loader = DataLoader(dataset_train, batch_size=64, shuffle=False)
val_loader = DataLoader(dataset_val, batch_size=64, shuffle=False)
test_loader = DataLoader(dataset_test, batch_size=64, shuffle=False)
</code></pre>
<h3 id="3-define-the-model">3. Define the model</h3>
<pre><code class="language-python">class CNN(nn.Module):
    def __init__(self, filters=2, kernel_size=11, units=32):
        super().__init__()
        self.conv = nn.Conv1d(1, filters, kernel_size)
        self.flatten = nn.Flatten()
        self.bn = nn.BatchNorm1d((2016 - kernel_size + 1) * filters)
        self.dropout = nn.Dropout(0.1)
        self.fc1 = nn.Linear((2016 - kernel_size + 1) * filters, units)
        self.fc2 = nn.Linear(units, 1)
        
        # weight initializiation as variancescaling in Keras
        nn.init.normal_(self.conv.weight, std=torch.sqrt(torch.tensor(1/2016)))
        self.conv.bias.data.fill_(0)
        
        nn.init.normal_(self.fc1.weight, std=torch.sqrt(torch.tensor(1/(2016 - kernel_size + 1) * filters)))
        self.fc1.bias.data.fill_(0)
        
        nn.init.normal_(self.fc2.weight, std=torch.sqrt(torch.tensor(1/units)))
        self.fc2.bias.data.fill_(0)
        
    def forward(self, x):
        x = self.conv(x)
        x = F.relu(x)
        x = self.flatten(x)
        x = self.bn(x)
        x = self.dropout(x)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x

model = CNN(2, 11)
model = model.to(device)
</code></pre>
<p>There are <em>two</em> points that need to be addressed.</p>
<p>One is the <mark>weight initialization</mark>. In Keras, we used <code>variancescaling</code> method to initialize the weights and <code>0</code> to initialize the biases. But in Pytorch, the default initialization method is not <code>variancescaling</code>. The detail of Pytorch initialization can be found in the <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#">docs</a>. So, we need to implement the initialization method by hand.</p>
<p>Indeed, the initialization issue is the key of the transfer. I have found that  if the weights are initialized differently, the optimized paramters in Keras are not suitable for the Pytorch code.</p>
<p>But the implementation here is not exactly same as the Keras. In Keras, <code>variancescaling</code> is to sample from a truncted normal distribution, but I did not make the truncted distribution. The results are still satisfactory, though.</p>
<p>The other is the weight decay in pytorch. While for standard SGD, L2 regularization can be repalced by weight decay through <a href="https://hxhc.github.io/post/l2-regularization-vs-weight-decay/">reparameterization</a>,  the <em>Adam</em> optimizer is somewhat different. In this case, the weight decay parameter <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>λ</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">\lambda&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> is not carefully chosen, but the model performance of pytorcg and keras are quite similar.</p>
<h3 id="4-train-the-model-2">4. Train the model</h3>
<pre><code class="language-python">def train(model, train_loader=train_loader, lr=1e-4, weight_decay=0.1):
    length = len(train_loader)
    loss_fn = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    for idx, (X, y) in enumerate(train_loader):
        optimizer.zero_grad()
        pred = model(X)
        loss = loss_fn(pred, y)

        loss.backward()
        optimizer.step()
        if idx % 50 == 0:
            loss_item, current = loss.item(), idx * len(X)
            print(f&quot;loss: {loss_item:&gt;7f}  [{current:&gt;5d}/{length:&gt;5d}]&quot;)
            
epochs = 2000
for t in range(epochs):
    print(f&quot;Epoch {t+1}\n-------------------------------&quot;)
    train(model, train_loader, lr=1e-4, weight_decay=0.1)
    
model.eval()
y_pred = model(Xtrain_t)

</code></pre>
<h2 id="pytorch_lightning-code">Pytorch_Lightning code</h2>
<p>Using pure pytorch is not as easy as Keras to create callbacks. But we can easily use <a href="https://pytorch-lightning.readthedocs.io/en/latest/">Pytorch_Lightning</a> to implement the callbacks.</p>
<p>The data peraperation code is the same as the pure Pytorch code, and the model definition section is also very similar.</p>
<h3 id="1-import-packages-3">1. Import packages</h3>
<pre><code class="language-python">import pytorch_lightning as pl
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import ModelCheckpoint
</code></pre>
<h3 id="2-define-the-model">2. Define the model</h3>
<pre><code class="language-python">class LitCNN(pl.LightningModule):
    def __init__(self, filters=2, kernel_size=11, units=32):
        super().__init__()
        self.conv = nn.Conv1d(1, filters, kernel_size)
        self.flatten = nn.Flatten()
        self.bn = nn.BatchNorm1d((2016-kernel_size+1)*filters)
        self.dropout = nn.Dropout(0.1)
        self.fc1 = nn.Linear((2016-kernel_size+1)*filters, units)
        self.fc2 = nn.Linear(units, 1)
        
        nn.init.normal_(self.conv.weight, std=torch.sqrt(torch.tensor(1/2016)))
        self.conv.bias.data.fill_(0)
        
        nn.init.normal_(self.fc1.weight, std=torch.sqrt(torch.tensor(1/(2016 - kernel_size + 1) * filters)))
        self.fc1.bias.data.fill_(0)
        
        nn.init.normal_(self.fc2.weight, std=torch.sqrt(torch.tensor(1/units)))
        self.fc2.bias.data.fill_(0)
        
    def forward(self, x):
        x = self.conv(x)
        x = F.relu(x)
        x = self.flatten(x)
        x = self.bn(x)
        x = self.dropout(x)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        return x
    
    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=1e-4, weight_decay=0.1)
        return optimizer

    def training_step(self, batch, batch_idx):
        X, y = batch
        ypred = self(X)
        loss = F.mse_loss(ypred, y)
        self.log(&quot;train_RMSE&quot;, torch.sqrt(loss))
        return loss
    
    def validation_step(self, batch, batch_idx):
        X, y = batch
        ypred = self(X)
        loss = F.mse_loss(ypred, y)
        self.log(&quot;val_RMSE&quot;, torch.sqrt(loss))

        return loss
        
    def test_step(self, batch, batch_idx):
        X, y = batch
        ypred = self(X)
        loss = F.mse_loss(ypred, y)
        self.log(&quot;test_RMSE&quot;, torch.sqrt(loss))
        return loss 

model_ckpt = LitCNN(2, 11)
</code></pre>
<h3 id="3-create-callbacks">3. Create callbacks</h3>
<pre><code class="language-python">
# earlystop (note the mini_delata should be reasonable)
earlystop = EarlyStopping(monitor='val_RMSE', min_delta=0.002, patience=500, mode='min')

# checkpoint (save the best model)
checkpoint = ModelCheckpoint(
    monitor=&quot;val_RMSE&quot;,
    dirpath=&quot;./checkpoint/&quot;,
    filename=&quot;best&quot;,
    save_top_k=1,
    mode=&quot;min&quot;,
    every_n_epochs=1,
    save_on_train_epoch_end=True,
    verbose=True
)
</code></pre>
<h3 id="4-train-the-model-3">4. Train the model</h3>
<pre><code class="language-python">trainer_ckpt = pl.Trainer(gpus=1, max_epochs=2000, progress_bar_refresh_rate=10,
                    callbacks=[earlystop, checkpoint])

trainer_ckpt.fit(model_ckpt, train_loader, val_loader)

# evaluate the last state
model_ckpt.eval()
y_pred_train = model_ckpt(Xtrain_t)
y_pred_val = model_ckpt(Xval_t)
y_pred_test = model_ckpt(Xtest_t)

print(torch.sqrt(F.mse_loss(y_pred_train, ytrain_t)))
print(torch.sqrt(F.mse_loss(y_pred_val, yval_t)))
print(torch.sqrt(F.mse_loss(y_pred_test, ytest_t)))

# evaluate the best state
model_loaded = LitCNN.load_from_checkpoint(checkpoint.best_model_path)

model_loaded.eval()
y_pred_train = model_loaded(Xtrain_t)
y_pred_val = model_loaded(Xval_t)
y_pred_test = model_loaded(Xtest_t)

print(F.mse_loss(y_pred_train, ytrain_t))
print(F.mse_loss(y_pred_val, yval_t))
print(F.mse_loss(y_pred_test, ytest_t))
</code></pre>

        </div>

        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://hxhc.xyz/tag/academic/">
            <span class="flex-auto">academic</span>
          </a>
        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://hxhc.xyz/tag/Software/">
            <span class="flex-auto">Software</span>
          </a>
        


        <div class="flex justify-between py-8">
          
            <div class="prev-post">
              <a href="https://hxhc.xyz/post/l2-regularization-vs-weight-decay/">
                <h3 class="post-title">
                  <i class="ri-arrow-left-line"></i>
                  L2 regularization vs Weight decay
                </h3>
              </a>
            </div>
          

          
            <div class="next-post">
              <a href="https://hxhc.xyz/post/SG_filter/">
                <h3 class="post-title">
                  Savitzky–Golay filter python implementation
                  <i class="ri-arrow-right-line"></i>
                </h3>
              </a>
            </div>
          
        </div>

        
          
            <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/gitalk/1.7.2/gitalk.css">
<script src="https://cdn.bootcdn.net/ajax/libs/gitalk/1.7.2/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'e8a467fa1547ec3d230a',
    clientSecret: '2a68cbc2236f231486004a9264438759e29d40f1',
    repo: 'hxhc.github.io',
    owner: 'hxhc',
    admin: ['hxhc'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

      </div>
    </div>


    <link rel="stylesheet" href="https://hxhc-blog.oss-cn-hangzhou.aliyuncs.com/media/prism-default-2.css">
    <script src="https://hxhc-blog.oss-cn-hangzhou.aliyuncs.com/media/prism-2.js"></script>

    <script>

    Prism.highlightAll()
    let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

    // This should probably be throttled.
    // Especially because it triggers during smooth scrolling.
    // https://lodash.com/docs/4.17.10#throttle
    // You could do like...
    // window.addEventListener("scroll", () => {
    //    _.throttle(doThatStuff, 100);
    // });
    // Only not doing it here to keep this Pen dependency-free.

    window.addEventListener("scroll", event => {
      let fromTop = window.scrollY;

      mainNavLinks.forEach((link, index) => {
        let section = document.getElementById(decodeURI(link.hash).substring(1));
        let nextSection = null
        if (mainNavLinks[index + 1]) {
          nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
        }
        if (section.offsetTop <= fromTop) {
          if (nextSection) {
            if (nextSection.offsetTop > fromTop) {
              link.classList.add("current");
            } else {
              link.classList.remove("current");
            }
          } else {
            link.classList.add("current");
          }
        } else {
          link.classList.remove("current");
        }
      });
    });


    document.addEventListener("DOMContentLoaded", function() {
      var lazyImages = [].slice.call(document.querySelectorAll(".post-feature-image.lazy"));

      if ("IntersectionObserver" in window) {
        let lazyImageObserver = new IntersectionObserver(function(entries, observer) {
          entries.forEach(function(entry) {
            if (entry.isIntersecting) {
              let lazyImage = entry.target
              lazyImage.style.backgroundImage = `url(${lazyImage.dataset.bg})`
              lazyImage.classList.remove("lazy")
              lazyImageObserver.unobserve(lazyImage)
            }
          });
        });

        lazyImages.forEach(function(lazyImage) {
          lazyImageObserver.observe(lazyImage)
        })
      } else {
        // Possibly fall back to a more compatible method here
      }
    });

    const menuContainer = document.querySelector('.menu-container')
    const menus = document.querySelectorAll('.menu-container .menu')
    const mask = document.querySelector('.mask')
    const contentWrapper = document.querySelector('.content-wrapper')
    const latestArticle = document.querySelector('.latest-article')
    const readMore = document.querySelector('.read-more')
    const indexPage = document.querySelector('.index-page')

    const isHome = location.pathname === '/'
    if (latestArticle) {
      latestArticle.style.display = isHome ? 'block' : 'none'
      readMore.style.display = isHome ? 'block' : 'none'
      indexPage.style.display = isHome ? 'none' : 'block'
    }

    const openMenu = () => {
      menuContainer.classList.add('open')
      menus.forEach(menu => {
        menu.classList.add('animated', 'fadeInLeft')
      })
      mask.classList.add('open')
      contentWrapper.classList.add('is-second')
    }

    const closeMenu = () => {
      menuContainer.classList.remove('open')
      menus.forEach(menu => {
        menu.classList.remove('animated', 'fadeInLeft')
      })
      mask.classList.remove('open')
      contentWrapper.classList.remove('is-second')
    }

    </script>

    <script src="//instant.page/5.1.1" type="module" integrity="sha384-MWfCL6g1OTGsbSwfuMHc8+8J2u71/LA8dzlIN3ycajckxuZZmF+DNjdm7O6H3PSq"></script>




  </body>
</html>
